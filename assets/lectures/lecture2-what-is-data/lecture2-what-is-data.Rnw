%% beamer/knitr slides 
%% for Statistical Modeling and Data Visualization course @ UMass
%% Nicholas Reich: nick [at] schoolph.umass.edu


\documentclass[table]{beamer}


\input{../../slide-includes/standard-knitr-beamer-preamble}

%	The following variables are assumed by the standard preamble:
%	Global variable containing module name:
\title{On statistics, sampling, and data structures}
%	Global variable containing module shortname:
%		(Currently unused, may be used in future.)
\newcommand{\ModuleShortname}{introRegression}
%	Global variable containing author name:
\author{Nicholas G Reich}
%	Global variable containing text of license terms:
\newcommand{\LicenseText}{Made available under the Creative Commons Attribution-ShareAlike 3.0 Unported License: http://creativecommons.org/licenses/by-sa/3.0/deed.en\textunderscore US }
%	Instructor: optional, can leave blank.
%		Recommended format: {Instructor: Jane Doe}
\newcommand{\Instructor}{}
%	Course: optional, can leave blank.
%		Recommended format: {Course: Biostatistics 101}
\newcommand{\Course}{}


\input{../../slide-includes/shortcuts}

\hypersetup{colorlinks,linkcolor=,urlcolor=MainColor}


<<echo=FALSE, warning=FALSE, message=FALSE>>=
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
@

%	******	Document body begins here	**********************

\begin{document}

%	Title page
\begin{frame}[plain]
	\titlepage
\end{frame}

%	******	Everything through the above line must be placed at
%		the top of any TeX file using the statsTeachR standard
%		beamer preamble. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% KEY POINTS
  % - data are our imperfect measures of the world, statistics helps us make sense of noisy observations (e.g. single binary outcome: polls, relationship with 2 or more variables: correlation, what fraction of earth's surface is covered in water?)
  % - randomness prevents us from seeing things perfectly, statistics are our glasses that reduce the blur
  % - appropriate understanding/use of uncertainty can be INFORMATIVE
  % - We can use math or algorithms to help us understand uncertainty
  % 
  % - types of variables
  % - populations vs. samples (types of samples)
  % - how to organize data in a tidy fashion?


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}

\begin{centering}
{\em Newton showed that the book of nature is written in the language of mathematics. Some chapters ... boil down to a clear-cut equation; but scholars who attempted to reduce biology, economics, and psychology to neat Newtonian equations \\ have discovered that these fields have a level of complexity \\ that makes such an aspiration futile. \\
This did not mean, however, that they gave up on mathematics. \\
{\bf A new branch of mathematics was developed over the last 200 years to deal with the more complex aspects of reality: statistics.}}

- Yuval Noah Harari \\ 
\em Sapiens: A Brief History of Humankind

\end{centering}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}

 \includegraphics[width=\textwidth]{figure-static/gelman-statistics-challenges.png}

\href{http://andrewgelman.com/2018/08/18/fallacy-excluded-middle-statistical-philosophy-edition/}{Andrew Gelman's blog}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Statistics brings data into focus}


<<sat1, echo=FALSE, message=FALSE, fig.height=5, fig.width=8, fig.show='hide', dev='png'>>=
library(mosaicData)
library(ggplot2)
theme_set(theme_bw())
data(SAT)
SAT$fracgrp = cut(SAT$frac, breaks=c(0, 22, 49, 81), 
                  labels=c("low", "medium", "high"))

ggplot(aes(salary, sat, color=fracgrp), data=SAT) +
    geom_point() + #geom_smooth(method="lm") + 
    xlab("est. average public school teacher salary") + 
    ylab("average total SAT score") +
    guides(color=FALSE) 
@

<<blur-figure, message=FALSE, echo=FALSE, fig.height=6, fig.width=8>>=
library(imager)
im <- load.image("figure/sat1-1.png")
im.blurry <- isoblur(im,10) 
par(mar=c(0,0,0,0))
plot(im.blurry, yaxt="n")
@


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Statistics does not eliminate noise}


<<sat2, echo=FALSE, message=FALSE, fig.height=5>>=
fm <- lm(sat ~ salary, data=SAT)
xpred <- seq(min(SAT$salary), max(SAT$salary), length.out = nrow(SAT))
ypred <- predict(fm, newdata=data.frame(salary=xpred))
tmp <- data.frame(xpred, ypred, fracgrp=SAT$fracgrp)
ggplot(aes(xpred, ypred, color=fracgrp), data=tmp) +
    geom_point() +  
    xlab("est. average public school teacher salary") + 
    ylab("average total SAT score") +
    guides(color=FALSE) 
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Statistics speaks a language of uncertainty}


<<sat3, echo=FALSE, message=FALSE, fig.height=5>>=
ggplot(aes(salary, sat, color=fracgrp), data=SAT) +
    geom_point() + geom_smooth(method="lm") + 
    xlab("est. average public school teacher salary") + 
    ylab("average total SAT score") +
    guides(color=FALSE) 
@

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Language of uncertainty: real-world politics edition}

Quotes from Nate Silver, Sunday Nov 6, 2016

\small 
\begin{itemize}
  \item ``... it shouldn’t be hard to see how Clinton could lose. She's up by about 3 percentage points nationally, and 3-point polling errors happen fairly often, including in the last two federal elections. Obama beat his polls by about 3 points in 2012, whereas Republicans beat their polls by 3 to 4 points in the 2014 midterms.''
  \item ``Right now, the tipping-point state in our forecast — the state that would provide the decisive 270th electoral vote if the polls got things exactly right — is New Hampshire. ... Clinton’s doing a little bit worse in the tipping-point state than she is overall — a sign that she might win the popular vote but lose the Electoral College.''
  \item ``To be honest, I’m kind of confused as to why people think it’s heretical for our model to give Trump a 1-in-3 chance — which does make him a fairly significant underdog, after all. ... the public polls — specifically including the highest-quality public polls — show a tight race in which turnout and late-deciding voters will determine the difference between a clear Clinton win, a narrow Clinton win and Trump finding his way to 270 electoral votes.''
\end{itemize}

\footnotesize
\href{https://fivethirtyeight.com/features/election-update-dont-ignore-the-polls-clinton-leads-but-its-a-close-race/}{FiveThirtyEight.com}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Language of uncertainty: flu forecasting edition}

 \includegraphics[width=\textwidth]{figure-static/flu-forecast-tweet.png}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}


\begin{center}
\huge
Data are measurements from our \\ imperfect, noisy world.
\end{center}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Key questions for any data analysis}


\begin{center}
\Large What population do your cases represent? 
\end{center}

\vspace{2em}

\begin{center}
\Large What variables do you have measurements on? 
\end{center}

\vspace{2em}

\begin{center}
\Large What are some sources of noise/variability?
\end{center}


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Where does the noise come from?}

<<showHeights, message=FALSE, echo=FALSE, fig.height=5, warning=FALSE>>=
library(alr3)
library(ggplot2)
data(heights)
qplot(Mheight, Dheight, data=heights, col="red", alpha=.5) +
    xlab("Mother's height (inches)") +
    ylab("Daughter's height (inches)") +
    theme_bw() + theme(legend.position="none") 
@

\end{frame}


% 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% 
% \begin{frame}{Where does the noise come from?}
% 
% 
% \includegraphics[width=\textwidth]{figure-static/polls-plot-20160904.png}
% 
% 
% \end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}


\begin{center}
\huge
Tidy data
\end{center}


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Tidy Data}

\begin{itemize}
  \item Tidy data is a very useful term. It was defined (although not conceived) by Hadley Wickham in \href{http://vita.had.co.nz/papers/tidy-data.html}{this paper}. 

  \item It is not the only acceptable format for data (there are times when other formats, such as a `wide-format' dataset may be needed), but it is a very common and widely used data structure.
  
  \item And, it plays very nicely with R.
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Tidy Data}

\includegraphics[width=\textwidth]{figure-static/tidy1.png}

\vspace{2em}

\footnotesize \href{https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf}{dplyr and tidyr cheatsheet}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Tidy Data}

\includegraphics[width=\textwidth]{figure-static/tidy2.png}

\vspace{2em}

\footnotesize \href{https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf}{dplyr and tidyr cheatsheet}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}


\begin{center}
\huge
Understanding Sampling
\end{center}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Sample size is tied to how much info is in your data}

Say we have a population of 1000 people where 600 have characteristic X and 400 do not. We want to estimate how many people have characteristic X. 



\small
<<resample>>=
groupA <- rep("A", 600)
groupB <- rep("B", 400)
population <- c(groupA, groupB)
sample(population, size = 5, replace=FALSE)
sample(population, size = 5, replace=FALSE)
@

\normalsize
How many people do you think we need to sample randomly to attain ``adequate'' precision on our estimate?


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}[fragile]{The size of your sample matters!}

Results from hypothetically sampling 5 people from the population 1000 times...

\small
<<fig.height=2.5>>=
nsim <- 1000
sample_props <- rep(NA, nsim)
for(i in 1:nsim) {
  tmp <- sample(population, size = 5, replace=FALSE)
  sample_props[i] <- sum(tmp=="A")/5
}
hist(sample_props, breaks=20, xlim=c(0,1))
abline(v=3/5, col="red")
@


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}[fragile]{The size of your sample matters!}

Results from hypothetically sampling 20 people from the population 1000 times...

\small
<<fig.height=2.5>>=
nsim <- 1000
nsamp <- 20
sample_props <- rep(NA, nsim)
for(i in 1:nsim) {
  tmp <- sample(population, size = nsamp, replace=FALSE)
  sample_props[i] <- sum(tmp=="A")/nsamp
}
hist(sample_props, breaks=20, xlim=c(0,1), ylim=c(0,10), freq = F)
abline(v=3/5, col="red")
@


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Beware of bias in your sampling!}

What if people without characteristic X were 2 times as likely to be sampled than those with it?

\small
<<resample-large-sample-bias>>=
weights <- c(rep(1,600), rep(2, 400))
sample2 <- sample(population, size = 100, 
                  replace=FALSE, prob=weights)
table(sample2)
@

\normalsize
In your groups: What fraction of your sample do you expect to have characteristic X?

%original fraction = 600/(600+400)
%updated fraction = 600/(600+400+400)

<<include=FALSE, eval=FALSE, fig.height=3>>=
nsim <- 1000
nsamp <- 100
sample_props <- rep(NA, nsim)
weights <- c(rep(1,600), rep(2, 400))
for(i in 1:nsim) {
  tmp <- sample(population, size = nsamp, 
                  replace=TRUE, prob=weights)
  sample_props[i] <- sum(tmp=="A")/nsamp
}
hist(sample_props, breaks=20, xlim=c(0,1), ylim=c(0,10), freq = F)
abline(v=6/14, col="red")
@

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Your project}

\begin{itemize}
    \item What types of variables are you collecting?
    \item What is the appropriate ``tidy data'' format for your data?
    \item Who are you collecting data on?
    \item What population are you trying to draw conclusions about?
    \item Do you expect your sample to be representative of the population? Why or why not?
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\end{document}